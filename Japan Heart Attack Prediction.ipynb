{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Region</th>\n",
       "      <th>Smoking_History</th>\n",
       "      <th>Diabetes_History</th>\n",
       "      <th>Hypertension_History</th>\n",
       "      <th>Cholesterol_Level</th>\n",
       "      <th>Physical_Activity</th>\n",
       "      <th>Diet_Quality</th>\n",
       "      <th>Alcohol_Consumption</th>\n",
       "      <th>...</th>\n",
       "      <th>Extra_Column_6</th>\n",
       "      <th>Extra_Column_7</th>\n",
       "      <th>Extra_Column_8</th>\n",
       "      <th>Extra_Column_9</th>\n",
       "      <th>Extra_Column_10</th>\n",
       "      <th>Extra_Column_11</th>\n",
       "      <th>Extra_Column_12</th>\n",
       "      <th>Extra_Column_13</th>\n",
       "      <th>Extra_Column_14</th>\n",
       "      <th>Extra_Column_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>Male</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>186.400209</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Low</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007901</td>\n",
       "      <td>0.794583</td>\n",
       "      <td>0.290779</td>\n",
       "      <td>0.497193</td>\n",
       "      <td>0.521995</td>\n",
       "      <td>0.799657</td>\n",
       "      <td>0.722398</td>\n",
       "      <td>0.148739</td>\n",
       "      <td>0.834010</td>\n",
       "      <td>0.061632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>Male</td>\n",
       "      <td>Urban</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>185.136747</td>\n",
       "      <td>Low</td>\n",
       "      <td>Good</td>\n",
       "      <td>Low</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083933</td>\n",
       "      <td>0.688951</td>\n",
       "      <td>0.830164</td>\n",
       "      <td>0.634490</td>\n",
       "      <td>0.302043</td>\n",
       "      <td>0.043683</td>\n",
       "      <td>0.451668</td>\n",
       "      <td>0.878671</td>\n",
       "      <td>0.535602</td>\n",
       "      <td>0.617825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>Male</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>210.696611</td>\n",
       "      <td>Low</td>\n",
       "      <td>Average</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227205</td>\n",
       "      <td>0.496344</td>\n",
       "      <td>0.752107</td>\n",
       "      <td>0.181501</td>\n",
       "      <td>0.629180</td>\n",
       "      <td>0.018276</td>\n",
       "      <td>0.063227</td>\n",
       "      <td>0.146512</td>\n",
       "      <td>0.997296</td>\n",
       "      <td>0.974455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>Urban</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>211.165478</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Good</td>\n",
       "      <td>High</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403182</td>\n",
       "      <td>0.741409</td>\n",
       "      <td>0.223968</td>\n",
       "      <td>0.329314</td>\n",
       "      <td>0.143191</td>\n",
       "      <td>0.907781</td>\n",
       "      <td>0.542322</td>\n",
       "      <td>0.922461</td>\n",
       "      <td>0.626217</td>\n",
       "      <td>0.228606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>Rural</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>223.814253</td>\n",
       "      <td>High</td>\n",
       "      <td>Good</td>\n",
       "      <td>High</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689787</td>\n",
       "      <td>0.904574</td>\n",
       "      <td>0.757098</td>\n",
       "      <td>0.337761</td>\n",
       "      <td>0.362375</td>\n",
       "      <td>0.728552</td>\n",
       "      <td>0.176699</td>\n",
       "      <td>0.484749</td>\n",
       "      <td>0.312091</td>\n",
       "      <td>0.452809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender Region Smoking_History Diabetes_History Hypertension_History  \\\n",
       "0   56    Male  Urban             Yes               No                   No   \n",
       "1   69    Male  Urban              No               No                   No   \n",
       "2   46    Male  Rural             Yes               No                   No   \n",
       "3   32  Female  Urban              No               No                   No   \n",
       "4   60  Female  Rural              No               No                   No   \n",
       "\n",
       "   Cholesterol_Level Physical_Activity Diet_Quality Alcohol_Consumption  ...  \\\n",
       "0         186.400209          Moderate         Poor                 Low  ...   \n",
       "1         185.136747               Low         Good                 Low  ...   \n",
       "2         210.696611               Low      Average            Moderate  ...   \n",
       "3         211.165478          Moderate         Good                High  ...   \n",
       "4         223.814253              High         Good                High  ...   \n",
       "\n",
       "   Extra_Column_6  Extra_Column_7  Extra_Column_8  Extra_Column_9  \\\n",
       "0        0.007901        0.794583        0.290779        0.497193   \n",
       "1        0.083933        0.688951        0.830164        0.634490   \n",
       "2        0.227205        0.496344        0.752107        0.181501   \n",
       "3        0.403182        0.741409        0.223968        0.329314   \n",
       "4        0.689787        0.904574        0.757098        0.337761   \n",
       "\n",
       "   Extra_Column_10 Extra_Column_11 Extra_Column_12  Extra_Column_13  \\\n",
       "0         0.521995        0.799657        0.722398         0.148739   \n",
       "1         0.302043        0.043683        0.451668         0.878671   \n",
       "2         0.629180        0.018276        0.063227         0.146512   \n",
       "3         0.143191        0.907781        0.542322         0.922461   \n",
       "4         0.362375        0.728552        0.176699         0.484749   \n",
       "\n",
       "   Extra_Column_14  Extra_Column_15  \n",
       "0         0.834010         0.061632  \n",
       "1         0.535602         0.617825  \n",
       "2         0.997296         0.974455  \n",
       "3         0.626217         0.228606  \n",
       "4         0.312091         0.452809  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/jacksonsorenson/Documents/Pyhton Projects/Japan Heart Attack/japan_heart_attack_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                          int64\n",
       "Gender                      object\n",
       "Region                      object\n",
       "Smoking_History             object\n",
       "Diabetes_History            object\n",
       "Hypertension_History        object\n",
       "Cholesterol_Level          float64\n",
       "Physical_Activity           object\n",
       "Diet_Quality                object\n",
       "Alcohol_Consumption         object\n",
       "Stress_Levels              float64\n",
       "BMI                        float64\n",
       "Heart_Rate                 float64\n",
       "Systolic_BP                float64\n",
       "Diastolic_BP               float64\n",
       "Family_History              object\n",
       "Heart_Attack_Occurrence     object\n",
       "Extra_Column_1             float64\n",
       "Extra_Column_2             float64\n",
       "Extra_Column_3             float64\n",
       "Extra_Column_4             float64\n",
       "Extra_Column_5             float64\n",
       "Extra_Column_6             float64\n",
       "Extra_Column_7             float64\n",
       "Extra_Column_8             float64\n",
       "Extra_Column_9             float64\n",
       "Extra_Column_10            float64\n",
       "Extra_Column_11            float64\n",
       "Extra_Column_12            float64\n",
       "Extra_Column_13            float64\n",
       "Extra_Column_14            float64\n",
       "Extra_Column_15            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.5377\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.54      0.68      5392\n",
      "           1       0.11      0.48      0.17       608\n",
      "\n",
      "    accuracy                           0.54      6000\n",
      "   macro avg       0.50      0.51      0.43      6000\n",
      "weighted avg       0.82      0.54      0.63      6000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ty/kkyy7c9s4059czrtyxg_0mz40000gn/T/ipykernel_69650/4262317067.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned['Alcohol_Consumption'].fillna(df_cleaned['Alcohol_Consumption'].mode()[0], inplace=True)\n",
      "/var/folders/ty/kkyy7c9s4059czrtyxg_0mz40000gn/T/ipykernel_69650/4262317067.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)\n",
      "/var/folders/ty/kkyy7c9s4059czrtyxg_0mz40000gn/T/ipykernel_69650/4262317067.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)\n",
      "/var/folders/ty/kkyy7c9s4059czrtyxg_0mz40000gn/T/ipykernel_69650/4262317067.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)\n",
      "/var/folders/ty/kkyy7c9s4059czrtyxg_0mz40000gn/T/ipykernel_69650/4262317067.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)\n",
      "/var/folders/ty/kkyy7c9s4059czrtyxg_0mz40000gn/T/ipykernel_69650/4262317067.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)\n",
      "/var/folders/ty/kkyy7c9s4059czrtyxg_0mz40000gn/T/ipykernel_69650/4262317067.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)\n",
      "/var/folders/ty/kkyy7c9s4059czrtyxg_0mz40000gn/T/ipykernel_69650/4262317067.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Drop extra columns\n",
    "extra_columns = [f'Extra_Column_{i}' for i in range(1, 16)]\n",
    "df_cleaned = df.drop(columns=extra_columns, errors='ignore')\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = ['Gender', 'Smoking_History', 'Diabetes_History', 'Hypertension_History',\n",
    "                    'Physical_Activity', 'Diet_Quality', 'Alcohol_Consumption', 'Family_History']\n",
    "numerical_cols = ['Age', 'Cholesterol_Level', 'Stress_Levels', 'BMI', 'Heart_Rate', 'Systolic_BP', 'Diastolic_BP']\n",
    "\n",
    "# Handle missing values\n",
    "df_cleaned['Alcohol_Consumption'].fillna(df_cleaned['Alcohol_Consumption'].mode()[0], inplace=True)\n",
    "for col in numerical_cols:\n",
    "    df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)\n",
    "\n",
    "# One-Hot Encoding for categorical features\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded_categorical = encoder.fit_transform(df_cleaned[categorical_cols])\n",
    "encoded_df = pd.DataFrame(encoded_categorical, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Combine categorical & numerical data\n",
    "df_final = pd.concat([df_cleaned[numerical_cols], encoded_df], axis=1)\n",
    "\n",
    "# Encode target variable (Yes=1, No=0)\n",
    "df_final['Heart_Attack_Occurrence'] = df_cleaned['Heart_Attack_Occurrence'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Drop low-importance features (selected based on your analysis)\n",
    "drop_cols = ['Cholesterol_Level',  'Diastolic_BP', 'Alcohol_Consumption_Low']\n",
    "df_final.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "# Split dataset\n",
    "X = df_final.drop(columns=['Heart_Attack_Occurrence'])\n",
    "y = df_final['Heart_Attack_Occurrence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "num_cols_to_scale = ['Age', 'Stress_Levels', 'BMI', 'Heart_Rate', 'Systolic_BP']  # Only important ones\n",
    "X_train[num_cols_to_scale] = scaler.fit_transform(X_train[num_cols_to_scale])\n",
    "X_test[num_cols_to_scale] = scaler.transform(X_test[num_cols_to_scale])\n",
    "\n",
    "# Add Feature Interaction Terms (Polynomial Features)\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression\n",
    "log_reg = LogisticRegression(class_weight='balanced', max_iter=500, random_state=42)\n",
    "log_reg.fit(X_train_poly, y_train)\n",
    "\n",
    "# Predict and Evaluate Model\n",
    "y_pred = log_reg.predict(X_test_poly)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print Results\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Accuracy: 0.8987\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      5392\n",
      "           1       0.00      0.00      0.00       608\n",
      "\n",
      "    accuracy                           0.90      6000\n",
      "   macro avg       0.45      0.50      0.47      6000\n",
      "weighted avg       0.81      0.90      0.85      6000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Add Feature Interaction Terms (Polynomial Features)\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=200, class_weight=\"balanced\", random_state=42)\n",
    "rf_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Predict and Evaluate Model\n",
    "y_pred_rf = rf_model.predict(X_test_poly)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "classification_rep_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "# Print Results\n",
    "print(f\"Random Forest Model Accuracy: {accuracy_rf:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_rep_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Features Influencing Heart Attacks:\n",
      "Systolic_BP: 0.0246\n",
      "Stress_Levels: 0.0244\n",
      "BMI: 0.0241\n",
      "Heart_Rate: 0.0240\n",
      "Age: 0.0189\n",
      "Alcohol_Consumption_Moderate: 0.0018\n",
      "Gender_Male: 0.0017\n",
      "Family_History_Yes: 0.0017\n",
      "Diet_Quality_Good: 0.0017\n",
      "Smoking_History_Yes: 0.0016\n",
      "Hypertension_History_Yes: 0.0016\n",
      "Physical_Activity_Moderate: 0.0016\n",
      "Diabetes_History_Yes: 0.0015\n",
      "Physical_Activity_Low: 0.0014\n",
      "Diet_Quality_Poor: 0.0014\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get feature importance from the trained Random Forest model\n",
    "feature_importance = rf_model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Sort features by importance\n",
    "important_features = sorted(zip(feature_names, feature_importance), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the top important features\n",
    "print(\"Top Features Influencing Heart Attacks:\")\n",
    "for feature, importance in important_features:  # Show top 10\n",
    "    print(f\"{feature}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Accuracy: 0.7773\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87      5392\n",
      "           1       0.09      0.13      0.11       608\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.49      0.49      0.49      6000\n",
      "weighted avg       0.81      0.78      0.80      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Train XGBoost Classifier\n",
    "xgb_model = XGBClassifier(scale_pos_weight=(y_train.value_counts()[0] / y_train.value_counts()[1]), random_state=42)\n",
    "xgb_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Predict and Evaluate Model\n",
    "y_pred_xgb = xgb_model.predict(X_test_poly)\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "classification_rep_xgb = classification_report(y_test, y_pred_xgb)\n",
    "\n",
    "# Print Results\n",
    "print(f\"XGBoost Model Accuracy: {accuracy_xgb:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_rep_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Random Forest Model Accuracy: 0.8987\n",
      "\n",
      "Updated Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      5392\n",
      "           1       0.00      0.00      0.00       608\n",
      "\n",
      "    accuracy                           0.90      6000\n",
      "   macro avg       0.45      0.50      0.47      6000\n",
      "weighted avg       0.81      0.90      0.85      6000\n",
      "\n",
      "Updated XGBoost Model Accuracy: 0.7773\n",
      "\n",
      "Updated XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87      5392\n",
      "           1       0.09      0.13      0.11       608\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.49      0.49      0.49      6000\n",
      "weighted avg       0.81      0.78      0.80      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Drop low-importance categorical features\n",
    "drop_cols = ['Diet_Quality', 'Physical_Activity', 'Diabetes_History', 'Hypertension_History', 'Smoking_History']\n",
    "\n",
    "# Drop these features from the dataset\n",
    "df_final.drop(columns=[col for col in drop_cols if col in df_final.columns], inplace=True)\n",
    "\n",
    "# Split dataset\n",
    "X = df_final.drop(columns=['Heart_Attack_Occurrence'])\n",
    "y = df_final['Heart_Attack_Occurrence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure numerical_cols only contains existing columns\n",
    "numerical_cols = ['Age', 'Stress_Levels', 'BMI', 'Heart_Rate', 'Systolic_BP']\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "# Add Feature Interaction Terms (Polynomial Features)\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=200, class_weight=\"balanced\", random_state=42)\n",
    "rf_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Predict and Evaluate Random Forest\n",
    "y_pred_rf = rf_model.predict(X_test_poly)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "classification_rep_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Updated Random Forest Model Accuracy: {accuracy_rf:.4f}\")\n",
    "print(\"\\nUpdated Random Forest Classification Report:\\n\", classification_rep_rf)\n",
    "\n",
    "# Train XGBoost Classifier\n",
    "xgb_model = XGBClassifier(scale_pos_weight=(y_train.value_counts()[0] / y_train.value_counts()[1]), random_state=42)\n",
    "xgb_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Predict and Evaluate XGBoost\n",
    "y_pred_xgb = xgb_model.predict(X_test_poly)\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "classification_rep_xgb = classification_report(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"Updated XGBoost Model Accuracy: {accuracy_xgb:.4f}\")\n",
    "print(\"\\nUpdated XGBoost Classification Report:\\n\", classification_rep_xgb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
